{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Supervised Machine Learning Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuzheqi0723/capstone-fraud-detection/blob/main/models/6_Supervised_Machine_Learning_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Application for real-time fraudulent transaction detection**"
      ],
      "metadata": {
        "id": "7FOAfnlsuPBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocessing the datasets"
      ],
      "metadata": {
        "id": "-5Qyo52ItYup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "TbXVRs2r3YCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lUWWfm3Z7-GU"
      },
      "outputs": [],
      "source": [
        "### import libraries ###\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Run it if it is the first time you running this notebook.\n",
        "\n",
        "# # # Mount your google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDJwKTdT8XTE",
        "outputId": "862aee92-fe7a-4ac9-ecb2-c757a2de03bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('/content/drive/MyDrive/Capstone/Data/X_raw.csv')\n",
        "X.drop(columns=['Unnamed: 0'], inplace=True) # drop index col\n",
        "\n",
        "y_df = pd.read_csv('/content/drive/MyDrive/Capstone/Data/y_raw.csv')\n",
        "y_df.drop(columns=['Unnamed: 0'], inplace=True) # drop index col\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "szSoXCxI8cMP",
        "outputId": "3a21e736-53e3-4ae6-b96e-725b6d301484"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id_01     id_02  id_05  id_06  id_11     id_12  id_13  id_15     id_16  \\\n",
              "0    0.0   70787.0    NaN    NaN  100.0  NotFound    NaN    New  NotFound   \n",
              "1   -5.0   98945.0    0.0   -5.0  100.0  NotFound   49.0    New  NotFound   \n",
              "2   -5.0  191631.0    0.0    0.0  100.0  NotFound   52.0  Found     Found   \n",
              "3   -5.0  221832.0    0.0   -6.0  100.0  NotFound   52.0    New  NotFound   \n",
              "4    0.0    7460.0    1.0    0.0  100.0  NotFound    NaN  Found     Found   \n",
              "\n",
              "   id_17  ...  V330  V331 V332 V333 V334 V335 V336 V337 V338 V339  \n",
              "0  166.0  ...   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  166.0  ...   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  121.0  ...  -1.0  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
              "3  225.0  ...  -1.0  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
              "4  166.0  ...   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 412 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b32314b0-97bf-40d6-8796-a0258b4a0ab0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>...</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>98945.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>49.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>191631.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>121.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>221832.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7460.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 412 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b32314b0-97bf-40d6-8796-a0258b4a0ab0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b32314b0-97bf-40d6-8796-a0258b4a0ab0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b32314b0-97bf-40d6-8796-a0258b4a0ab0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y_df.to_numpy().reshape(-1) # convert type and reshape y\n",
        "\n",
        "\n",
        "X = X.drop(columns=['dist1', 'D11'], inplace=False) # all nan values\n",
        "X.name = 'X'\n",
        "\n",
        "# print(X.shape)"
      ],
      "metadata": {
        "id": "nnFcMeoh2_ai"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balance the X\n",
        "Balaced X  does not improve the performance of ML Models. \n",
        "\n",
        "So the following part are all comment out. \n",
        "\n",
        "But we still keep all these codes for potencially used in the future. "
      ],
      "metadata": {
        "id": "X5oOHHC8Kcjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X['isFraud']=y\n",
        "# print(len(X[X['isFraud']==1])) # number of fraud\n",
        "# print(len(X[X['isFraud']==0])/len(X)) # ratio of non fraud\n",
        "\n",
        "# # resample to make a balanced dataset\n",
        "# df_balance = X.groupby('isFraud').apply(lambda x: x.sample(n=10000)).reset_index(drop = True)\n",
        "# print(df_balance.shape)\n",
        "\n",
        "# X = df_balance.drop(columns=['isFraud'], inplace=False) # drop id and label\n",
        "# y = df_balance['isFraud']"
      ],
      "metadata": {
        "id": "Kz_VvI6EKXDb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create encoding for categorical vairables\n"
      ],
      "metadata": {
        "id": "ZcPww3pA1oFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = X.dtypes[X.dtypes == np.object].index.tolist() # list of columns with categorical variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4g6p3ny2wDx",
        "outputId": "55af9e9f-7b0c-43ef-b4fd-efce758c48df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create ordinal encoders for categorical variables\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "oe = OrdinalEncoder( dtype=int)\n",
        "oe.fit(X[categorical_columns])\n",
        "X[categorical_columns] = oe.transform(X[categorical_columns]) "
      ],
      "metadata": {
        "id": "UV4DsB3x2jM-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset to train and test"
      ],
      "metadata": {
        "id": "YvbekTcy3Ix2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test\\\n",
        "   = train_test_split(X, y, test_size=0.2, random_state=697)\n"
      ],
      "metadata": {
        "id": "7hxM7OO088_W"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fill Nan values (Part B)\n",
        "Fill with mean and most frequent values. fit and train using pipeline."
      ],
      "metadata": {
        "id": "TONmjZrFeuKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    1.b fill with **mean** value of the column\n",
        ">numerical 'id_XX'\n",
        "\n",
        "    2.b fill with **mean** value of the column using sklearn.impute.\n",
        "\n",
        ">card1 - card6: payment card information.Such as card type, card category, issue bank, country, etc.\n",
        "\n",
        ">addr: both addresses are for purchaser.\n",
        "addr1 as billing region.\n",
        "addr2 as billing country.\n",
        "\n",
        ">dist: distances between (not limited) billing address, mailing address, zip code, IP address, phone area, etc.\n",
        "<br>\n",
        "\n",
        "    2.c fill with **most frequent value** in the column.\n",
        "  >C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
        "  \n",
        "  >D1-D15: timedelta, such as days between previous transaction, etc.\n",
        "<br>"
      ],
      "metadata": {
        "id": "pCTONV2TjHO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_null = X.isnull().sum(axis=0).to_frame() # count Nans in every col.\n",
        "X_null.rename(columns={0: '#_Nans'}, inplace=True) # rename cols."
      ],
      "metadata": {
        "id": "z2tXhJfpE_7U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "### Step 1:\n",
        "# filter out the cols with Nans.\n",
        "X_null = X.isnull().sum(axis=0).to_frame() # count Nans in every col.\n",
        "X_null.rename(columns={0: '#_Nans'}, inplace=True) # rename cols.\n",
        "X_NanCols = X_null[X_null['#_Nans']>0].index # get a series contains all the names of cols with Nan.\n",
        "\n",
        "X_fullCols = X_null[X_null['#_Nans']==0].index   # column names without NA\n",
        "\n",
        "# make lists, indicating which stratage will be used in imputing the cols.\n",
        "cols_fill_mean = []\n",
        "cols_fill_freq = []\n",
        "\n",
        "for col in X_NanCols:\n",
        "  if str(col).startswith('C'): # cols C1-C1\n",
        "    cols_fill_freq.append(col)\n",
        "  elif str(col).startswith('D'): # cols D1-D15 and 'Device ...' which has been filled previously.\n",
        "    cols_fill_freq.append(col)\n",
        "  else:\n",
        "    cols_fill_mean.append(col) # cols id_XX and cols has already been filled with other startages earlier.\n",
        "\n",
        "# make all the cols still included in the following processing\n",
        "cols_fill_freq.extend(X_fullCols.to_list())"
      ],
      "metadata": {
        "id": "ltk5LAhP9q-X"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2:\n",
        "# instantiate the imputers, within a pipeline\n",
        "# imputer imputes with the mean\n",
        "imp_mean = Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))])\n",
        "\n",
        "\n",
        "# imputer imputes with 'most_frequent'\n",
        "imp_freq = Pipeline(steps=[('imputer',SimpleImputer(missing_values=np.nan, strategy='most_frequent'))])\n",
        "\n",
        "\n",
        "                                                             "
      ],
      "metadata": {
        "id": "RrbPkPYW-tbF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3:\n",
        "# put the features list and the transformers together by col transformer.\n",
        "imp_preprocessor = ColumnTransformer(transformers=[('imp_mean', imp_mean, cols_fill_mean),\\\n",
        "                                                   ('imp_freq',imp_freq,cols_fill_freq)])#,remainder='passthrough' )\n",
        "    "
      ],
      "metadata": {
        "id": "PIbK1spB4E1P"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4:\n",
        "# fit and trans the datasets with 'imp_preprocessor'.\n",
        "imp_preprocessor.fit(X_train)\n",
        "\n",
        "X_train = imp_preprocessor.transform(X_train)\n",
        "X_test = imp_preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "2Ur8xYzDyx8m"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(list(X.columns))"
      ],
      "metadata": {
        "id": "xqhanF2fwf_c"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save(\"X_train.npy\", X_train)\n",
        "# !cp X_train.npy \"drive/MyDrive/Capstone/Data/\"\n",
        "# np.save(\"X_test.npy\", X_train)\n",
        "# !cp X_test.npy \"drive/MyDrive/Capstone/Data/\""
      ],
      "metadata": {
        "id": "xAXCt-Ov3ZIL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save(\"y_train.npy\", y_train)\n",
        "# !cp y_train.npy \"drive/MyDrive/Capstone/Data/\"\n",
        "# np.save(\"y_test.npy\", y_test)\n",
        "# !cp y_test.npy \"drive/MyDrive/Capstone/Data/\""
      ],
      "metadata": {
        "id": "iWS1tgvb4Qmq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from joblib import dump, load\n",
        "# dump(imp_preprocessor, \"nan_processor.joblib\")\n",
        "# !cp nan_processor.joblib \"drive/MyDrive/Capstone/Data/\""
      ],
      "metadata": {
        "id": "TK4fCFRMrSQc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Machine Learning Models"
      ],
      "metadata": {
        "id": "UW1dKzBTEbIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import f1_score \n",
        "# F1 = 2 * (precision * recall) / (precision + recall)\n",
        "# The recall is the ratio tp / (tp + fn)\n",
        "# The recall is intuitively the ability of the classifier to find all the positive samples\n",
        "# The precision is the ratio tp / (tp + fp) \n",
        "# The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# [[true negatives, false negatives], \n",
        "# [true positives, false positives]]."
      ],
      "metadata": {
        "id": "OyUNijV00n7R"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-NN Classifier\n",
        "Too slow.</br>\n",
        "Will not feed this model to our final system.\n",
        "\n"
      ],
      "metadata": {
        "id": "_Ushmanc1VOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "def knn_clf(n_neighbors=5):\n",
        "    \n",
        "    print(\"The number of nearest neighbors is: {}\".format(n_neighbors))\n",
        "    \n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    \n",
        "    Acu = accuracy_score(y_test, y_pred)\n",
        "    print(\"the accuracy score is: {}\".format(round(Acu, 4)))\n",
        "\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    print(\"the F1 score is: {}\".format(round(F1, 4)))\n",
        "\n",
        "    Mtrx = confusion_matrix(y_test, y_pred, labels = [0, 1])\n",
        "    print(\"the confusion matrix score is:\\n{}\\n\".format(Mtrx))\n",
        "    \n",
        "\n",
        "    return knn\n"
      ],
      "metadata": {
        "id": "zKuU6Su21Str"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neighbors=list(range(1,11,3))\n",
        "\n",
        "# for n in neighbors:\n",
        "#     knn_clf(n)"
      ],
      "metadata": {
        "id": "jNgF4GI21cMu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree\n"
      ],
      "metadata": {
        "id": "Iw81qEyU1lpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def tree_clf(max_depth=5):\n",
        "    \n",
        "    print(\"The number of depth is: {}\".format(max_depth))\n",
        "    \n",
        "    dtree = DecisionTreeClassifier(max_depth=max_depth, criterion = 'entropy')\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "\n",
        "    Acu = accuracy_score(y_test, y_pred)\n",
        "    print(\"the accuracy score is: {}\".format(round(Acu, 4)))\n",
        "\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    print(\"the F1 score is: {}\".format(round(F1, 4)))\n",
        "\n",
        "    Mtrx = confusion_matrix(y_test, y_pred, labels = [0, 1])\n",
        "    print(\"the confusion matrix score is:\\n{}\\n\".format(Mtrx))\n",
        "\n",
        "    return dtree\n"
      ],
      "metadata": {
        "id": "8tGgK-rjeMmc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depths=list(range(3,21,3))\n",
        "\n",
        "# for n in depths:\n",
        "#     tree_clf(n)"
      ],
      "metadata": {
        "id": "L2Hydpx92Ox-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depths=list(range(12,18,1))\n",
        "\n",
        "# for n in depths:\n",
        "#     tree_clf(n)"
      ],
      "metadata": {
        "id": "2coR6qDY2RyK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### result for unbalanced X:\n",
        "The number of depth is: 12\n",
        "the accuracy score is: 0.9612\n",
        "the F1 score is: 0.7172\n",
        "the confusion matrix score is:\n",
        "[[24597   240]\n",
        " [  805  1325]]\n",
        "\n",
        "The number of depth is: 13\n",
        "the accuracy score is: 0.9607\n",
        "the F1 score is: 0.7248\n",
        "the confusion matrix score is:\n",
        "[[24509   328]\n",
        " [  733  1397]]\n",
        "\n",
        "The number of depth is: 14\n",
        "the accuracy score is: 0.961\n",
        "the F1 score is: 0.7273\n",
        "the confusion matrix score is:\n",
        "[[24510   327]\n",
        " [  726  1404]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.9617\n",
        "the F1 score is: 0.7344\n",
        "the confusion matrix score is:\n",
        "[[24506   331]\n",
        " [  702  1428]]\n",
        "\n",
        "The number of depth is: 16\n",
        "the accuracy score is: 0.9605\n",
        "the F1 score is: 0.7292\n",
        "the confusion matrix score is:\n",
        "[[24466   371]\n",
        " [  695  1435]]\n",
        "\n",
        "The number of depth is: 17\n",
        "the accuracy score is: 0.9603\n",
        "the F1 score is: 0.7337\n",
        "the confusion matrix score is:\n",
        "[[24423   414]\n",
        " [  656  1474]]\n",
        "\n",
        "\n",
        " #### result for balanced X:\n",
        " The number of depth is: 12\n",
        "the accuracy score is: 0.8572\n",
        "the F1 score is: 0.8528\n",
        "the confusion matrix score is:\n",
        "[[1775  213]\n",
        " [ 358 1654]]\n",
        "\n",
        "The number of depth is: 13\n",
        "the accuracy score is: 0.8528\n",
        "the F1 score is: 0.8488\n",
        "the confusion matrix score is:\n",
        "[[1758  230]\n",
        " [ 359 1653]]\n",
        "\n",
        "The number of depth is: 14\n",
        "the accuracy score is: 0.855\n",
        "the F1 score is: 0.8524\n",
        "the confusion matrix score is:\n",
        "[[1745  243]\n",
        " [ 337 1675]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.8515\n",
        "the F1 score is: 0.8495\n",
        "the confusion matrix score is:\n",
        "[[1729  259]\n",
        " [ 335 1677]]\n",
        "\n",
        "The number of depth is: 16\n",
        "the accuracy score is: 0.8538\n",
        "the F1 score is: 0.8524\n",
        "the confusion matrix score is:\n",
        "[[1726  262]\n",
        " [ 323 1689]]\n",
        "\n",
        "The number of depth is: 17\n",
        "the accuracy score is: 0.8492\n",
        "the F1 score is: 0.8489\n",
        "the confusion matrix score is:\n",
        "[[1703  285]\n",
        " [ 318 1694]]"
      ],
      "metadata": {
        "id": "1IA78WjYKxzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best paras\n",
        "best_DT = DecisionTreeClassifier(max_depth=16, criterion = 'entropy')\n",
        "best_DT.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYEGUotdzar_",
        "outputId": "e559d8ae-52a2-4fa6-9ee7-d4236bff3d10"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=16)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "99OJFSZEnHlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def rf_clf(max_depth=5):\n",
        "    \n",
        "    print(\"The number of depth is: {}\".format(max_depth))\n",
        "    \n",
        "    rf = RandomForestClassifier(max_depth = max_depth)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "\n",
        "    Acu = accuracy_score(y_test, y_pred)\n",
        "    print(\"the accuracy score is: {}\".format(round(Acu, 4)))\n",
        "\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    print(\"the F1 score is: {}\".format(round(F1, 4)))\n",
        "\n",
        "    Mtrx = confusion_matrix(y_test, y_pred, labels = [0, 1])\n",
        "    print(\"the confusion matrix score is:\\n{}\\n\".format(Mtrx))\n",
        "\n",
        "    return rf"
      ],
      "metadata": {
        "id": "YfbMB_TZnK6i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depths=list(range(5,25,3))\n",
        "\n",
        "# for n in depths:\n",
        "#     rf_clf(n)"
      ],
      "metadata": {
        "id": "760kldKPnLOR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depths=list(range(10,36,5))\n",
        "\n",
        "# for n in depths:\n",
        "#     rf_clf(n)"
      ],
      "metadata": {
        "id": "WXCijKJv4Z61"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best paras\n",
        "best_rf= RandomForestClassifier(max_depth = 35)\n",
        "best_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycIjuJ2w0SfX",
        "outputId": "00d5c63a-b5e4-4756-9051-e36a0e5b30ac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=35)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unbalanced X\n",
        "The number of depth is: 10\n",
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
        "  \n",
        "the accuracy score is: 0.9585\n",
        "the F1 score is: 0.6612\n",
        "the confusion matrix score is:\n",
        "[[24754    83]\n",
        " [ 1037  1093]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.9644\n",
        "the F1 score is: 0.723\n",
        "the confusion matrix score is:\n",
        "[[24752    85]\n",
        " [  876  1254]]\n",
        "\n",
        "The number of depth is: 20\n",
        "the accuracy score is: 0.967\n",
        "the F1 score is: 0.7494\n",
        "the confusion matrix score is:\n",
        "[[24744    93]\n",
        " [  798  1332]]\n",
        "\n",
        "The number of depth is: 25\n",
        "the accuracy score is: 0.9681\n",
        "the F1 score is: 0.7616\n",
        "the confusion matrix score is:\n",
        "[[24736   101]\n",
        " [  758  1372]]\n",
        "\n",
        "The number of depth is: 30\n",
        "the accuracy score is: 0.9693\n",
        "the F1 score is: 0.7699\n",
        "the confusion matrix score is:\n",
        "[[24751    86]\n",
        " [  743  1387]]\n",
        "\n",
        "The number of depth is: 35  \n",
        "the accuracy score is: 0.969\n",
        "the F1 score is: 0.7687\n",
        "the confusion matrix score is:\n",
        "[[24742    95]\n",
        " [  741  1389]]\n",
        "\n",
        "\n",
        "#### balanced X\n",
        "The number of depth is: 10\n",
        "the accuracy score is: 0.8625\n",
        "the F1 score is: 0.8546\n",
        "the confusion matrix score is:\n",
        "[[1834  154]\n",
        " [ 396 1616]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.883\n",
        "the F1 score is: 0.8787\n",
        "the confusion matrix score is:\n",
        "[[1837  151]\n",
        " [ 317 1695]]\n",
        "\n",
        "The number of depth is: 20\n",
        "the accuracy score is: 0.889\n",
        "the F1 score is: 0.886\n",
        "the confusion matrix score is:\n",
        "[[1831  157]\n",
        " [ 287 1725]]\n",
        "\n",
        "The number of depth is: 25\n",
        "the accuracy score is: 0.8908\n",
        "the F1 score is: 0.8878\n",
        "the confusion matrix score is:\n",
        "[[1834  154]\n",
        " [ 283 1729]]\n",
        "\n",
        "The number of depth is: 30\n",
        "the accuracy score is: 0.895\n",
        "the F1 score is: 0.8925\n",
        "the confusion matrix score is:\n",
        "[[1836  152]\n",
        " [ 268 1744]]\n",
        "\n",
        "The number of depth is: 35\n",
        "the accuracy score is: 0.8925\n",
        "the F1 score is: 0.8897\n",
        "the confusion matrix score is:\n",
        "[[1835  153]\n",
        " [ 277 1735]]"
      ],
      "metadata": {
        "id": "uJ8jJwNPNPx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machines"
      ],
      "metadata": {
        "id": "6lDB7DaMnyUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
        "\n",
        "def svc_machine():\n",
        "    \n",
        "    svc_m = SVC()\n",
        "    svc_m.fit(X_train, y_train)\n",
        "    y_pred = svc_m.predict(X_test)\n",
        "\n",
        "    Acu = accuracy_score(y_test, y_pred)\n",
        "    print(\"the accuracy score is: {}\".format(round(Acu, 4)))\n",
        "\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    print(\"the F1 score is: {}\".format(round(F1, 4)))\n",
        "\n",
        "    Mtrx = confusion_matrix(y_test, y_pred, labels = [0, 1])\n",
        "    print(\"the confusion matrix score is:\\n{}\\n\".format(Mtrx))\n",
        "\n",
        "    return svc_machine"
      ],
      "metadata": {
        "id": "0UREG_nRn4RL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svc_machine()"
      ],
      "metadata": {
        "id": "hL3oTUgN3V4s"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBooster"
      ],
      "metadata": {
        "id": "zGzW_3Q_pA0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def xgb_clf(max_depth=5):\n",
        "    \n",
        "    print(\"The number of depth is: {}\".format(max_depth))\n",
        "    \n",
        "    xgb = XGBClassifier(max_depth = max_depth)\n",
        "    xgb.fit(X_train, y_train)\n",
        "    y_pred = xgb.predict(X_test)\n",
        "\n",
        "    Acu = accuracy_score(y_test, y_pred)\n",
        "    print(\"the accuracy score is: {}\".format(round(Acu, 4)))\n",
        "\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    print(\"the F1 score is: {}\".format(round(F1, 4)))\n",
        "\n",
        "    Mtrx = confusion_matrix(y_test, y_pred, labels = [0, 1])\n",
        "    print(\"the confusion matrix score is:\\n{}\\n\".format(Mtrx))\n",
        "\n",
        "    return xgb_clf"
      ],
      "metadata": {
        "id": "9J8hjHfipKy8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depths=list(range(10,30,5))\n",
        "\n",
        "# for n in depths:\n",
        "#     xgb_clf(n)\n",
        "\n"
      ],
      "metadata": {
        "id": "2r3Ja2N0pjEd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best paras\n",
        "best_xgb = XGBClassifier(max_depth = 30)\n",
        "best_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zyvgXdV905kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### unbalanced X\n",
        "The number of depth is: 5\n",
        "the accuracy score is: 0.9664\n",
        "the F1 score is: 0.7487\n",
        "the confusion matrix score is:\n",
        "[[24714   123]\n",
        " [  782  1348]]\n",
        "\n",
        "The number of depth is: 10\n",
        "the accuracy score is: 0.9766\n",
        "the F1 score is: 0.8333\n",
        "the confusion matrix score is:\n",
        "[[24755    82]\n",
        " [  550  1580]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.9775\n",
        "the F1 score is: 0.8406\n",
        "the confusion matrix score is:\n",
        "[[24756    81]\n",
        " [  527  1603]]\n",
        "\n",
        "The number of depth is: 20\n",
        "the accuracy score is: 0.9776\n",
        "the F1 score is: 0.8417\n",
        "the confusion matrix score is:\n",
        "[[24757    80]\n",
        " [  524  1606]]\n",
        "\n",
        "#### balanced X\n",
        "\n",
        "The number of depth is: 5\n",
        "the accuracy score is: 0.8975\n",
        "the F1 score is: 0.895\n",
        "the confusion matrix score is:\n",
        "[[1843  145]\n",
        " [ 265 1747]]\n",
        "\n",
        "The number of depth is: 10\n",
        "the accuracy score is: 0.9112\n",
        "the F1 score is: 0.9097\n",
        "the confusion matrix score is:\n",
        "[[1856  132]\n",
        " [ 223 1789]]\n",
        "\n",
        "The number of depth is: 15\n",
        "the accuracy score is: 0.9168\n",
        "the F1 score is: 0.9152\n",
        "the confusion matrix score is:\n",
        "[[1870  118]\n",
        " [ 215 1797]]\n",
        "\n",
        "The number of depth is: 20\n",
        "the accuracy score is: 0.9142\n",
        "the F1 score is: 0.9129\n",
        "the confusion matrix score is:\n",
        "[[1859  129]\n",
        " [ 214 1798]]"
      ],
      "metadata": {
        "id": "eIJFMd62NcRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## persist the model for future use without having to retrain."
      ],
      "metadata": {
        "id": "TG7-mUkBJH3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "dump(best_DT, 'DesicionTree.joblib') \n",
        "dump(best_rf, 'RandomForest.joblib')\n",
        "\n",
        "!cp DesicionTree.joblib \"drive/MyDrive/Capstone/Data/\"\n",
        "!cp RandomForest.joblib \"drive/MyDrive/Capstone/Data/\""
      ],
      "metadata": {
        "id": "u4lQpeNysKVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb.save_model('XGBooster.json')\n",
        "!cp XGBooster.json \"drive/MyDrive/Capstone/Data/\""
      ],
      "metadata": {
        "id": "h6-KAE6GB20s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "951cn2BQ5O2d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}